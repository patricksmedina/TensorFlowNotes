{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we bring back the same graph, this time we tell TensorFlow to stop the gradient flow into the first network.  This effectively freezes it from being trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "reg_saver = tf.train.import_meta_graph('/Users/patrickmedina/Desktop/regression/model-891.meta')\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "tf_x = graph.get_tensor_by_name(\"x:0\")\n",
    "tf_y = graph.get_tensor_by_name(\"y:0\")\n",
    "\n",
    "a_0 = graph.get_tensor_by_name(\"a:0\")\n",
    "b_0 = graph.get_tensor_by_name(\"b:0\")\n",
    "y_hat = graph.get_tensor_by_name(\"regression:0\")\n",
    "y_hat = tf.stop_gradient(y_hat)\n",
    "\n",
    "# extend the graph\n",
    "a_1 = tf.Variable(0.5, dtype=tf.float32, name=\"a_1\")\n",
    "b_1 = tf.Variable(0.5, dtype=tf.float32, name=\"b_1\")\n",
    "y_hat_2 = tf.add(tf.multiply(a_1, y_hat), b_1, name=\"regression_2\")\n",
    "\n",
    "# define a new loss function\n",
    "loss = tf.subtract(y_hat_2, tf_y) ** 2\n",
    "loss = tf.reduce_mean(loss)\n",
    "\n",
    "ao = tf.train.AdamOptimizer(learning_rate=1e-2, name='Adam_3')\n",
    "ts = ao.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/patrickmedina/Desktop/regression/model-891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.745913, 4.7164893]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "# initialize the variables in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# reload the saved graph\n",
    "reg_saver.restore(sess, \"/Users/patrickmedina/Desktop/regression/model-891\")\n",
    "\n",
    "# print the saved variables to check they are the same\n",
    "print(sess.run([a_0, b_0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting epoch 0\n[INFO] Loss at step 0: 30.557727813720703\n[INFO] Starting epoch 1\n[INFO] Loss at step 0: 36.318111419677734\n[INFO] Starting epoch 2\n[INFO] Loss at step 0: 9.83077621459961\n[INFO] Starting epoch 3\n[INFO] Loss at step 0: 2.0161874294281006\n[INFO] Starting epoch 4\n[INFO] Loss at step 0: 7.6009674072265625\n[INFO] Starting epoch 5\n[INFO] Loss at step 0: 1.3311092853546143\n[INFO] Starting epoch 6\n[INFO] Loss at step 0: 1.1798031330108643\n[INFO] Starting epoch 7\n[INFO] Loss at step 0: 1.481640338897705\n[INFO] Starting epoch 8\n[INFO] Loss at step 0: 0.911202609539032\n[INFO] Starting epoch 9\n[INFO] Loss at step 0: 1.8647263050079346\n[INFO] Starting epoch 10\n[INFO] Loss at step 0: 1.2193058729171753\n[INFO] Starting epoch 11\n[INFO] Loss at step 0: 0.8939501047134399\n[INFO] Starting epoch 12\n[INFO] Loss at step 0: 0.5959290266036987\n[INFO] Starting epoch 13\n[INFO] Loss at step 0: 1.4993646144866943\n[INFO] Starting epoch 14\n[INFO] Loss at step 0: 1.0972175598144531\n[INFO] Starting epoch 15\n[INFO] Loss at step 0: 1.370703935623169\n[INFO] Starting epoch 16\n[INFO] Loss at step 0: 0.5637376308441162\n[INFO] Starting epoch 17\n[INFO] Loss at step 0: 1.294264554977417\n[INFO] Starting epoch 18\n[INFO] Loss at step 0: 0.3990003168582916\n[INFO] Starting epoch 19\n[INFO] Loss at step 0: 0.9574995040893555\n[INFO] Starting epoch 20\n[INFO] Loss at step 0: 1.131819486618042\n[INFO] Starting epoch 21\n[INFO] Loss at step 0: 1.2770322561264038\n[INFO] Starting epoch 22\n[INFO] Loss at step 0: 1.7225124835968018\n[INFO] Starting epoch 23\n[INFO] Loss at step 0: 1.129528284072876\n[INFO] Starting epoch 24\n[INFO] Loss at step 0: 1.4809637069702148\n[INFO] Starting epoch 25\n[INFO] Loss at step 0: 0.9464443325996399\n[INFO] Starting epoch 26\n[INFO] Loss at step 0: 0.832795262336731\n[INFO] Starting epoch 27\n[INFO] Loss at step 0: 0.8566070795059204\n[INFO] Starting epoch 28\n[INFO] Loss at step 0: 1.3072407245635986\n[INFO] Starting epoch 29\n[INFO] Loss at step 0: 1.1133930683135986\n[INFO] Starting epoch 30\n[INFO] Loss at step 0: 0.7794663310050964\n[INFO] Starting epoch 31\n[INFO] Loss at step 0: 1.09707772731781\n[INFO] Starting epoch 32\n[INFO] Loss at step 0: 0.4456815719604492\n[INFO] Starting epoch 33\n[INFO] Loss at step 0: 2.611046552658081\n[INFO] Starting epoch 34\n[INFO] Loss at step 0: 0.8965749740600586\n[INFO] Starting epoch 35\n[INFO] Loss at step 0: 0.6950610876083374\n[INFO] Starting epoch 36\n[INFO] Loss at step 0: 1.076101303100586\n[INFO] Starting epoch 37\n[INFO] Loss at step 0: 0.35954421758651733\n[INFO] Starting epoch 38\n[INFO] Loss at step 0: 2.0379014015197754\n[INFO] Starting epoch 39\n[INFO] Loss at step 0: 1.0400713682174683\n[INFO] Starting epoch 40\n[INFO] Loss at step 0: 1.3924585580825806\n[INFO] Starting epoch 41\n[INFO] Loss at step 0: 2.0370841026306152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting epoch 42\n[INFO] Loss at step 0: 2.370272636413574\n[INFO] Starting epoch 43\n[INFO] Loss at step 0: 0.8908463716506958\n[INFO] Starting epoch 44\n[INFO] Loss at step 0: 0.6521652936935425\n[INFO] Starting epoch 45\n[INFO] Loss at step 0: 0.7773493528366089\n[INFO] Starting epoch 46\n[INFO] Loss at step 0: 1.5710139274597168\n[INFO] Starting epoch 47\n[INFO] Loss at step 0: 1.790196418762207\n[INFO] Starting epoch 48\n[INFO] Loss at step 0: 1.117257833480835\n[INFO] Starting epoch 49\n[INFO] Loss at step 0: 0.5758978128433228\n[INFO] Starting epoch 50\n[INFO] Loss at step 0: 1.0580493211746216\n[INFO] Starting epoch 51\n[INFO] Loss at step 0: 0.4915386140346527\n[INFO] Starting epoch 52\n[INFO] Loss at step 0: 0.8638102412223816\n[INFO] Starting epoch 53\n[INFO] Loss at step 0: 0.713320255279541\n[INFO] Starting epoch 54\n[INFO] Loss at step 0: 0.4017605781555176\n[INFO] Starting epoch 55\n[INFO] Loss at step 0: 1.188022255897522\n[INFO] Starting epoch 56\n[INFO] Loss at step 0: 0.6601468920707703\n[INFO] Starting epoch 57\n[INFO] Loss at step 0: 1.388641595840454\n[INFO] Starting epoch 58\n[INFO] Loss at step 0: 0.7154994010925293\n[INFO] Starting epoch 59\n[INFO] Loss at step 0: 0.7194469571113586\n[INFO] Starting epoch 60\n[INFO] Loss at step 0: 1.7833681106567383\n[INFO] Starting epoch 61\n[INFO] Loss at step 0: 1.4956142902374268\n[INFO] Starting epoch 62\n[INFO] Loss at step 0: 0.3233054280281067\n[INFO] Starting epoch 63\n[INFO] Loss at step 0: 0.8840471506118774\n[INFO] Starting epoch 64\n[INFO] Loss at step 0: 1.8779995441436768\n[INFO] Starting epoch 65\n[INFO] Loss at step 0: 1.6293647289276123\n[INFO] Starting epoch 66\n[INFO] Loss at step 0: 0.46100157499313354\n[INFO] Starting epoch 67\n[INFO] Loss at step 0: 1.5607664585113525\n[INFO] Starting epoch 68\n[INFO] Loss at step 0: 1.7566343545913696\n[INFO] Starting epoch 69\n[INFO] Loss at step 0: 1.593719244003296\n[INFO] Starting epoch 70\n[INFO] Loss at step 0: 0.6502886414527893\n[INFO] Starting epoch 71\n[INFO] Loss at step 0: 0.7358973622322083\n[INFO] Starting epoch 72\n[INFO] Loss at step 0: 1.84709894657135\n[INFO] Starting epoch 73\n[INFO] Loss at step 0: 0.6213106513023376\n[INFO] Starting epoch 74\n[INFO] Loss at step 0: 0.846919059753418\n[INFO] Starting epoch 75\n[INFO] Loss at step 0: 1.5984528064727783\n[INFO] Starting epoch 76\n[INFO] Loss at step 0: 0.951156735420227\n[INFO] Starting epoch 77\n[INFO] Loss at step 0: 0.4666481912136078\n[INFO] Starting epoch 78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loss at step 0: 0.2629030644893646\n[INFO] Starting epoch 79\n[INFO] Loss at step 0: 0.6441296339035034\n[INFO] Starting epoch 80\n[INFO] Loss at step 0: 0.4644384980201721\n[INFO] Starting epoch 81\n[INFO] Loss at step 0: 0.8916559219360352\n[INFO] Starting epoch 82\n[INFO] Loss at step 0: 1.366497278213501\n[INFO] Starting epoch 83\n[INFO] Loss at step 0: 0.294782817363739\n[INFO] Starting epoch 84\n[INFO] Loss at step 0: 3.49717378616333\n[INFO] Starting epoch 85\n[INFO] Loss at step 0: 0.93653804063797\n[INFO] Starting epoch 86\n[INFO] Loss at step 0: 1.2069025039672852\n[INFO] Starting epoch 87\n[INFO] Loss at step 0: 0.4381698966026306\n[INFO] Starting epoch 88\n[INFO] Loss at step 0: 0.8008621335029602\n[INFO] Starting epoch 89\n[INFO] Loss at step 0: 1.513906717300415\n[INFO] Starting epoch 90\n[INFO] Loss at step 0: 1.3449785709381104\n[INFO] Starting epoch 91\n[INFO] Loss at step 0: 2.386894941329956\n[INFO] Starting epoch 92\n[INFO] Loss at step 0: 0.5544506311416626\n[INFO] Starting epoch 93\n[INFO] Loss at step 0: 1.8477973937988281\n[INFO] Starting epoch 94\n[INFO] Loss at step 0: 0.8310530781745911\n[INFO] Starting epoch 95\n[INFO] Loss at step 0: 1.5497815608978271\n[INFO] Starting epoch 96\n[INFO] Loss at step 0: 0.9928112030029297\n[INFO] Starting epoch 97\n[INFO] Loss at step 0: 0.6122808456420898\n[INFO] Starting epoch 98\n[INFO] Loss at step 0: 1.1770689487457275\n[INFO] Starting epoch 99\n[INFO] Loss at step 0: 0.41599225997924805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/patrickmedina/Desktop/regression_3/model-891'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the data\n",
    "x = np.random.normal(size=(100, )).astype(np.float32)\n",
    "y = 10 * x + 5 + np.random.normal(size=(100, )).astype(np.float32)\n",
    "\n",
    "for ep in range(100):\n",
    "    print(\"[INFO] Starting epoch {}\".format(ep))\n",
    "    idx = np.arange(100)\n",
    "    np.random.shuffle(idx)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "\n",
    "    for i in range(10):\n",
    "        start = 10 * i\n",
    "        stop = start + 10\n",
    "        feed_dict = {tf_x: x[start:stop], tf_y: y[start:stop]}\n",
    "        \n",
    "        l, _ = sess.run([loss, ts], feed_dict=feed_dict)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"[INFO] Loss at step {0}: {1}\".format(i, l))\n",
    "\n",
    "reg_saver.save(sess, \"/Users/patrickmedina/Desktop/regression_3/model\", ep * i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe, the first two variables from the original graph are unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.745913, 4.7164893, 1.024, 0.24384697]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run([a_0, b_0, a_1, b_1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
